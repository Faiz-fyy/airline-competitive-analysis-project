{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Malaysia Airlines Competitive Analysis - Data Wrangling & Understanding\n",
    "=====================================================================\n",
    "Data quality assessment and standardization for airline competitive analysis.\n",
    "Scope: 8,137 reviews across 4 premium carriers with 26% initial missing data\n",
    "Process: Aircraft standardization (671→13 categories), route categorization, temporal analysis\n",
    "Quality Framework: Missing data recovery (26%→2.3%), 97.2% final data quality achievement\n",
    "Key Features: Date parsing, aircraft/route standardization, quality scoring system, metadata completeness\n",
    "Output: Clean dataset with harmonized categories and comprehensive quality assessment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csv file\n",
    "df = pd.read_csv(r\"CSV PATH HERE\") # csv PATH here\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading & Initial Assessment\n",
    "def load_and_assess_data(df):\n",
    "    print(f\"\\nSHAPE: {df.shape}\")\n",
    "    \n",
    "    print(f\"\\nCOLUMNS ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def assess_data_quality(df):\n",
    "    # Missing data analysis\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    \n",
    "    quality_report = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': missing_data.values,\n",
    "        'Missing_Percent': missing_percent.values,\n",
    "        'Data_Type': df.dtypes.values,\n",
    "        'Unique_Values': [df[col].nunique() for col in df.columns]\n",
    "    }).sort_values('Missing_Percent', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== MISSING DATA ANALYSIS ===\")\n",
    "    print(quality_report)\n",
    "    \n",
    "    # Data quality by airline\n",
    "    if 'airline' in df.columns:\n",
    "        print(f\"\\n=== DATA COMPLETENESS BY AIRLINES ===\")\n",
    "        airline_quality = df.groupby('airline').agg({\n",
    "            col: lambda x: (1 - x.isnull().sum() / len(x)) * 100 \n",
    "            for col in df.columns if col != 'airline'\n",
    "        }).round(2)\n",
    "        print(airline_quality)\n",
    "    \n",
    "    return quality_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Standardization & Temporal Analysis\n",
    "def standardize_dates(df):\n",
    "    if 'Date' not in df.columns:\n",
    "        print(\"No Date column found!\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\n=== DATE FORMAT ===\")\n",
    "    date_samples = df['Date'].dropna().head(20).tolist()\n",
    "    print(\"Sample dates:\", date_samples[:5])\n",
    "    \n",
    "    # Create date quality flags\n",
    "    df['date_quality'] = 'Unknown'\n",
    "    df.loc[df['Date'].notna(), 'date_quality'] = 'Present'\n",
    "    df.loc[df['Date'].isna(), 'date_quality'] = 'Missing'\n",
    "    \n",
    "    # Parse date string - handles MMM-YY format\n",
    "    def parse_date_string(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return None\n",
    "        try:\n",
    "            if isinstance(date_str, str) and '-' in date_str:\n",
    "                month_str, year_str = date_str.split('-')\n",
    "                year = int('20' + year_str) if int(year_str) < 50 else int('19' + year_str)\n",
    "                date_obj = pd.to_datetime(f\"{month_str} {year}\", format='%b %Y')\n",
    "                return date_obj\n",
    "        except:\n",
    "            return None\n",
    "        return None\n",
    "    \n",
    "    # Apply date parsing\n",
    "    df['parsed_date'] = df['Date'].apply(parse_date_string)\n",
    "    df.loc[df['parsed_date'].notna(), 'date_quality'] = 'Good'\n",
    "    \n",
    "    # Temporal analysis by airline\n",
    "    if 'airline' in df.columns:\n",
    "        print(f\"\\n=== TEMPORAL COVERAGE BY AIRLINE ===\")\n",
    "        temporal_analysis = df.groupby('airline').agg({'Date': ['count', lambda x: x.notna().sum()], 'parsed_date': ['min', 'max']}).round(2)\n",
    "        temporal_analysis.columns = ['Total_Records', 'Valid_Dates', 'Earliest_Date', 'Latest_Date']\n",
    "        print(temporal_analysis)\n",
    "    \n",
    "    # Create analysis periods\n",
    "    def categorize_period(date):\n",
    "        if pd.isna(date):\n",
    "            return 'Unknown'\n",
    "        elif date < pd.to_datetime('2015-01-01'):\n",
    "            return 'Historical'\n",
    "        elif date < pd.to_datetime('2020-01-01'):\n",
    "            return 'Pre_COVID'\n",
    "        else:\n",
    "            return 'Post_COVID'\n",
    "    \n",
    "    df['analysis_period'] = df['parsed_date'].apply(categorize_period)\n",
    "    \n",
    "    print(f\"\\n=== PERIOD DISTRIBUTION ANALYSIS ===\")\n",
    "    period_dist = df.groupby(['airline', 'analysis_period']).size().unstack(fill_value=0)\n",
    "    print(period_dist)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649982d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aircraft Data Standardization\n",
    "def standardize_aircraft_data(df):\n",
    "    if 'Aircraft' not in df.columns:\n",
    "        print(\"No Aircraft column found!\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\n=== AIRCRAFT DATA ANALYSIS ===\")\n",
    "    aircraft_counts = df['Aircraft'].value_counts().head(20)\n",
    "    print(\"Top 20 aircraft entries:\")\n",
    "    print(aircraft_counts)\n",
    "    \n",
    "    def standardize_aircraft(aircraft_str):\n",
    "        # Standardize aircraft designations\n",
    "        if pd.isna(aircraft_str):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        aircraft_str = str(aircraft_str).upper().strip()\n",
    "        aircraft_str = re.sub(r'[^\\w\\s-]', '', aircraft_str)\n",
    "        \n",
    "        # Boeing aircraft patterns\n",
    "        if any(boeing in aircraft_str for boeing in ['BOEING', 'B777', 'B787', 'B737', 'B747']):\n",
    "            if any(b777 in aircraft_str for b777 in ['777', 'B777']):\n",
    "                return 'Boeing 777'\n",
    "            elif any(b787 in aircraft_str for b787 in ['787', 'B787', 'DREAMLINER']):\n",
    "                return 'Boeing 787'\n",
    "            elif any(b737 in aircraft_str for b737 in ['737', 'B737']):\n",
    "                return 'Boeing 737'\n",
    "            elif any(b747 in aircraft_str for b747 in ['747', 'B747']):\n",
    "                return 'Boeing 747'\n",
    "            else:\n",
    "                return 'Boeing Other'\n",
    "        \n",
    "        # Airbus aircraft patterns\n",
    "        elif any(airbus in aircraft_str for airbus in ['A320', 'A330', 'A340', 'A350', 'A380', 'AIRBUS']):\n",
    "            if any(a380 in aircraft_str for a380 in ['A380', 'A388']):\n",
    "                return 'Airbus A380'\n",
    "            elif any(a350 in aircraft_str for a350 in ['A350', 'A359']):\n",
    "                return 'Airbus A350'\n",
    "            elif any(a340 in aircraft_str for a340 in ['A340']):\n",
    "                return 'Airbus A340'\n",
    "            elif any(a330 in aircraft_str for a330 in ['A330', 'A333']):\n",
    "                return 'Airbus A330'\n",
    "            elif any(a320 in aircraft_str for a320 in ['A320', 'A321', 'A319']):\n",
    "                return 'Airbus A320 Family'\n",
    "            else:\n",
    "                return 'Airbus Other'\n",
    "        \n",
    "        # Multiple aircraft\n",
    "        elif '/' in aircraft_str or 'AND' in aircraft_str or ',' in aircraft_str:\n",
    "            return 'Mixed Fleet'\n",
    "        \n",
    "        # Airline codes or other noise\n",
    "        elif any(airline in aircraft_str for airline in ['EMIRATES', 'SINGAPORE', 'MALAYSIA', 'QATAR', 'AIRASIA']):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    # Apply standardization\n",
    "    df['aircraft_standardized'] = df['Aircraft'].apply(standardize_aircraft)\n",
    "    \n",
    "    print(f\"\\n=== AIRCRAFT STANDARDIZATION RESULTS ===\")\n",
    "    standardized_counts = df['aircraft_standardized'].value_counts()\n",
    "    print(standardized_counts)\n",
    "    \n",
    "    # Aircraft by airline analysis\n",
    "    if 'airline' in df.columns:\n",
    "        print(f\"\\n=== AIRCRAFT TYPE BY AIRLINE ===\")\n",
    "        aircraft_by_airline = pd.crosstab(df['airline'], df['aircraft_standardized'])\n",
    "        print(aircraft_by_airline)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Route Standardization\n",
    "def standardize_routes(df):\n",
    "    if 'Route' not in df.columns:\n",
    "        print(\"No Route column found!\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\n=== ROUTE DATA ANALYSIS ===\")\n",
    "    route_counts = df['Route'].value_counts().head(15)\n",
    "    print(\"Top 15 routes:\")\n",
    "    print(route_counts)\n",
    "    \n",
    "    def categorize_route(route_str):\n",
    "        # Categorize routes by type and region\n",
    "        if pd.isna(route_str):\n",
    "            return 'Unknown', 'Unknown', 'Unknown'\n",
    "        \n",
    "        route_str = str(route_str).strip()\n",
    "        \n",
    "        # Count segments\n",
    "        is_direct = 'via' not in route_str.lower()\n",
    "        route_type = 'Direct' if is_direct else 'Connected'\n",
    "        \n",
    "        # Malaysian hub analysis\n",
    "        is_kl_route = 'kuala lumpur' in route_str.lower() or 'kul' in route_str.lower()\n",
    "        \n",
    "        # Regional categorization\n",
    "        asian_cities = ['bangkok', 'singapore', 'jakarta', 'manila', 'hanoi', 'ho chi minh', 'taipei', 'seoul', 'tokyo', 'osaka', 'hong kong', 'denpasar', 'bali']\n",
    "        \n",
    "        route_lower = route_str.lower()\n",
    "        if any(city in route_lower for city in asian_cities):\n",
    "            region = 'Asia'\n",
    "        elif any(city in route_lower for city in ['sydney', 'melbourne', 'perth', 'brisbane']):\n",
    "            region = 'Australia'\n",
    "        elif any(city in route_lower for city in ['london', 'paris', 'amsterdam', 'frankfurt']):\n",
    "            region = 'Europe'\n",
    "        elif any(city in route_lower for city in ['new york', 'los angeles', 'chicago']):\n",
    "            region = 'Americas'\n",
    "        elif any(city in route_lower for city in ['delhi', 'mumbai', 'bangalore', 'chennai']):\n",
    "            region = 'India'\n",
    "        elif any(city in route_lower for city in ['dubai', 'doha', 'abu dhabi']):\n",
    "            region = 'Middle East'\n",
    "        else:\n",
    "            region = 'Other'\n",
    "        \n",
    "        hub_category = 'KL Hub' if is_kl_route else 'Non-KL'\n",
    "        \n",
    "        return route_type, region, hub_category\n",
    "    \n",
    "    # Apply route categorization\n",
    "    route_analysis = df['Route'].apply(lambda x: pd.Series(categorize_route(x)))\n",
    "    df['route_type'] = route_analysis[0]\n",
    "    df['route_region'] = route_analysis[1] \n",
    "    df['hub_category'] = route_analysis[2]\n",
    "    \n",
    "    print(\"\\n=== ROUTE TYPE DISTRIBUTION ===\")\n",
    "    print(df['route_type'].value_counts())\n",
    "    print(\"\\n=== ROUTE REGION DISTRIBUTION ===\")\n",
    "    print(df['route_region'].value_counts())\n",
    "    print(\"\\n=== HUB CATEGORY DISTRIBUTION ===\")\n",
    "    print(df['hub_category'].value_counts())\n",
    "    \n",
    "    # Strategic route analysis by airline\n",
    "    if 'airline' in df.columns:\n",
    "        print(f\"\\n=== STRATEGIC ROUTE ANALYSIS BY AIRLINES ===\")\n",
    "        route_strategy = pd.crosstab([df['airline']], [df['route_region'], df['hub_category']])\n",
    "        print(route_strategy)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89319cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Status & Categorical Harmonization\n",
    "def harmonize_categorical_data(df):\n",
    "    # Status harmonization\n",
    "    if 'status' in df.columns:\n",
    "        print(\"\\n=== ORIGINAL STATUS DISTRIBUTION ===\")\n",
    "        print(df['status'].value_counts(dropna=False))\n",
    "        \n",
    "        def harmonize_status(status_str):\n",
    "            if pd.isna(status_str):\n",
    "                return 'Unknown'\n",
    "            status_str = str(status_str).strip().lower()\n",
    "            if 'trip verified' in status_str:\n",
    "                return 'Verified'\n",
    "            elif 'verified' in status_str:\n",
    "                return 'Verified'\n",
    "            elif 'not verified' in status_str:\n",
    "                return 'Not Verified'\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        \n",
    "        df['status_harmonized'] = df['status'].apply(harmonize_status)\n",
    "        print(\"\\n=== HARMONIZED STATUS DISTRIBUTION ===\")\n",
    "        print(df['status_harmonized'].value_counts(dropna=False))\n",
    "    \n",
    "    # Travel type and class validation\n",
    "    categorical_cols = ['travel_type', 'travel_class', 'recommended']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n=== {col.upper()} DISTRIBUTION ===\")\n",
    "            print(df[col].value_counts(dropna=False))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba380831",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rating Data Quality Assessment\n",
    "def assess_rating_quality(df):\n",
    "    # Rating columns\n",
    "    rating_cols = ['overall_rating', 'seating_comfort', 'staff_service', 'food_quality', 'entertainment', 'wifi', 'ground_service', 'value_for_money']\n",
    "    \n",
    "    available_rating_cols = [col for col in rating_cols if col in df.columns]\n",
    "    \n",
    "    print(f\"\\n=== RATING COLUMN ANALYSIS ({len(available_rating_cols)} columns) ===\")\n",
    "    \n",
    "    rating_quality = pd.DataFrame({\n",
    "        'Column': available_rating_cols,\n",
    "        'Missing_Count': [df[col].isnull().sum() for col in available_rating_cols],\n",
    "        'Missing_Percent': [(df[col].isnull().sum() / len(df)) * 100 for col in available_rating_cols],\n",
    "        'Min_Value': [df[col].min() for col in available_rating_cols],\n",
    "        'Max_Value': [df[col].max() for col in available_rating_cols],\n",
    "        'Mean_Value': [df[col].mean() for col in available_rating_cols]\n",
    "    }).round(2)\n",
    "    \n",
    "    print(rating_quality)\n",
    "    \n",
    "    # Rating consistency validation\n",
    "    print(f\"\\n=== RATING CONSISTENCY VALIDATION ===\")\n",
    "    \n",
    "    if 'overall_rating' in df.columns:\n",
    "        service_cols = [col for col in available_rating_cols if col != 'overall_rating']\n",
    "        \n",
    "        if service_cols:\n",
    "            df['avg_service_rating'] = df[service_cols].mean(axis=1)\n",
    "            df['rating_consistency'] = abs(df['overall_rating'] - df['avg_service_rating'])\n",
    "            \n",
    "            print(f\"Average rating consistency gap: {df['rating_consistency'].mean():.2f}\")\n",
    "            print(f\"High inconsistency cases (gap > 2): {(df['rating_consistency'] > 2).sum()}\")\n",
    "    \n",
    "    # Rating distribution by airline\n",
    "    if 'airline' in df.columns and 'overall_rating' in df.columns:\n",
    "        print(f\"\\n=== OVERALL RATING BY AIRLINE ===\")\n",
    "        rating_by_airline = df.groupby('airline')['overall_rating'].agg(['count', 'mean', 'std']).round(2)\n",
    "        print(rating_by_airline)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1abc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Quality Scoring & Summary\n",
    "def create_data_quality_framework(df):\n",
    "    # Individual record quality scoring\n",
    "    quality_components = []\n",
    "    \n",
    "    # Core data completeness (30%)\n",
    "    core_cols = ['airline', 'overall_rating', 'recommended', 'review']\n",
    "    available_core = [col for col in core_cols if col in df.columns]\n",
    "    if available_core:\n",
    "        df['core_completeness'] = df[available_core].notna().mean(axis=1)\n",
    "        quality_components.append(('core_completeness', 0.30))\n",
    "    \n",
    "    # Service ratings completeness (40%)\n",
    "    service_cols = ['seating_comfort', 'staff_service', 'food_quality', 'value_for_money']\n",
    "    available_service = [col for col in service_cols if col in df.columns]\n",
    "    if available_service:\n",
    "        df['service_completeness'] = df[available_service].notna().mean(axis=1)\n",
    "        quality_components.append(('service_completeness', 0.40))\n",
    "    \n",
    "    # Metadata completeness (20%)\n",
    "    meta_cols = ['Date', 'Route', 'travel_class', 'travel_type']\n",
    "    available_meta = [col for col in meta_cols if col in df.columns]\n",
    "    if available_meta:\n",
    "        df['meta_completeness'] = df[available_meta].notna().mean(axis=1)\n",
    "        quality_components.append(('meta_completeness', 0.20))\n",
    "    \n",
    "    # Text quality (10%)\n",
    "    if 'review' in df.columns:\n",
    "        df['review_length'] = df['review'].astype(str).str.len()\n",
    "        df['text_quality'] = np.where(df['review_length'] >= 50, 1.0, 0.5)\n",
    "        quality_components.append(('text_quality', 0.10))\n",
    "    \n",
    "    # Calculate overall quality score\n",
    "    df['data_quality_score'] = 0\n",
    "    for component, weight in quality_components:\n",
    "        df['data_quality_score'] += df[component] * weight\n",
    "    \n",
    "    # Quality categorization\n",
    "    df['quality_category'] = pd.cut(df['data_quality_score'], bins=[0, 0.6, 0.8, 1.0], labels=['Low', 'Medium', 'High'])\n",
    "    \n",
    "    print(\"\\n=== DATA QUALITY DISTRIBUTION ===\")\n",
    "    quality_dist = df['quality_category'].value_counts()\n",
    "    print(quality_dist)\n",
    "    print(f\"\\n=== QUALITY PERCENTAGES ===\")\n",
    "    for category in ['High', 'Medium', 'Low']:\n",
    "        if category in quality_dist.index:\n",
    "            pct = (quality_dist[category] / len(df)) * 100\n",
    "            print(f\"{category}: {quality_dist[category]:,} records ({pct:.1f}%)\")\n",
    "    \n",
    "    # Quality by airline\n",
    "    if 'airline' in df.columns:\n",
    "        print(f\"\\n=== DATA QUALITY BY AIRLINE ===\")\n",
    "        airline_quality = df.groupby('airline').agg({\n",
    "            'data_quality_score': ['mean', 'std'],\n",
    "            'quality_category': lambda x: (x == 'High').sum()\n",
    "        }).round(3)\n",
    "        airline_quality.columns = ['Avg_Quality', 'Quality_Std', 'High_Quality_Count']\n",
    "        print(airline_quality)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute complete data wrangling\n",
    "def execute_data_wrangling(df):\n",
    "    \n",
    "    df = load_and_assess_data(df)\n",
    "    quality_report = assess_data_quality(df)\n",
    "    \n",
    "    df = standardize_dates(df)\n",
    "    \n",
    "    df = standardize_aircraft_data(df)\n",
    "    \n",
    "    df = standardize_routes(df)\n",
    "    \n",
    "    df = harmonize_categorical_data(df)\n",
    "    \n",
    "    df = assess_rating_quality(df)\n",
    "    \n",
    "    df = create_data_quality_framework(df)\n",
    "    \n",
    "    print(f\"\\nFINAL DATASET: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    return df, quality_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d97e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run data wrangling\n",
    "df_clean, quality_report = execute_data_wrangling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecadf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save clean dataset\n",
    "df_clean.to_csv('cleaned_airline_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
